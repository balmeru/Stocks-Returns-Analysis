{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c816de6-67d3-4853-a113-255ff68f4ac4",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:21px; font-family:'Times New Roman';\">\n",
    "Read report dates data \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afee8605-6296-4589-abee-6cb79cadc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csv_file_path = '/Users/balmeru/Downloads/QQQQ.csv'\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab8791d-1ca9-4297-b6dd-68658ab24e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fyr'] = pd.to_numeric(df['fyr'], errors='coerce')\n",
    "df = df.sort_values(by=['tic', 'fyearq', 'fqtr'])\n",
    "ticker_change = df['tic'] != df['tic'].shift(1)\n",
    "df['fyr_change_dummy'] = ((df['fyr'] != df['fyr'].shift(1)) & (~ticker_change)).astype(int)\n",
    "\n",
    "# Fill the first occurrence of each ticker group with 0\n",
    "df.loc[df.groupby('tic').head(1).index, 'fyr_change_dummy'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d34524-f484-4809-bbdb-cd18cac24d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times fyr_change_dummy is equal to 1: 2188\n"
     ]
    }
   ],
   "source": [
    "count_fyr_change_dummy_1 = df['fyr_change_dummy'].sum()\n",
    "print(f\"Number of times fyr_change_dummy is equal to 1: {count_fyr_change_dummy_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f477780-3aa4-49a8-aa44-10c46165f17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where either fyearq or fqtr is NaN: 0\n"
     ]
    }
   ],
   "source": [
    "nan_count = df[df['fyearq'].isna() | df['fqtr'].isna()].shape[0]\n",
    "\n",
    "print(\"Number of rows where either fyearq or fqtr is NaN:\", nan_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932f7348-c9d0-48a4-8a2f-dd68d0785821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall length of the DataFrame: 1085915\n"
     ]
    }
   ],
   "source": [
    "df_length = len(df)\n",
    "\n",
    "print(\"Overall length of the DataFrame:\", df_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f906af3-ec33-4694-9a42-20691ee72a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated cases based on tic, fyearq, and fqtr: 20779\n"
     ]
    }
   ],
   "source": [
    "duplicated_cases = df[df.duplicated(subset=['tic', 'fyearq', 'fqtr'], keep=False)].shape[0]\n",
    "\n",
    "print(\"Number of duplicated cases based on tic, fyearq, and fqtr:\", duplicated_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069ddf40-c305-4d94-b917-b3583f38410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique duplicated combinations: 10304\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated(subset=['tic', 'fyearq', 'fqtr'], keep=False)]\n",
    "\n",
    "# Count unique combinations of tic, fyearq, and fqtr among the duplicated rows\n",
    "unique_duplicates_count = duplicated_rows.drop_duplicates(subset=['tic', 'fyearq', 'fqtr']).shape[0]\n",
    "\n",
    "print(\"Number of unique duplicated combinations:\", unique_duplicates_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f67280-309e-49bb-a6d1-23dd82dc9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where the same year and quarter is duplicated for the same ticker:\n",
      "        GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "630256  20783  1992-03-31    1992     3    6   INDL      C      D     STD   \n",
      "630257  20783  1992-03-31    1992     3    6   INDL      C      D     STD   \n",
      "630258  20783  1992-06-30    1992     4    6   INDL      C      D     STD   \n",
      "630259  20783  1992-06-30    1992     4    6   INDL      C      D     STD   \n",
      "630260  20783  1992-09-30    1993     1    6   INDL      C      D     STD   \n",
      "\n",
      "          tic  ...   dvpq     ibq      lseq       ltq   pstkq     teqq  txdbq  \\\n",
      "630256  0090A  ...  0.327  90.634  1938.769  1038.029     NaN  900.740    NaN   \n",
      "630257  0090A  ...  0.327  90.634  1938.769  1038.029     NaN  900.740    NaN   \n",
      "630258  0090A  ...  0.328  26.200  1932.309   997.431  28.846  934.878    NaN   \n",
      "630259  0090A  ...  0.328  26.200  1932.309   997.431  28.846  934.878    NaN   \n",
      "630260  0090A  ...  0.327  67.609  2046.837  1081.666     NaN  965.171    NaN   \n",
      "\n",
      "        costat   prccq  fyr_change_dummy  \n",
      "630256       I  46.375                 0  \n",
      "630257       I  46.375                 0  \n",
      "630258       I  46.250                 0  \n",
      "630259       I  46.250                 0  \n",
      "630260       I  51.500                 0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated(subset=['tic', 'fyearq', 'fqtr'], keep=False)]\n",
    "\n",
    "print(\"Rows where the same year and quarter is duplicated for the same ticker:\")\n",
    "print(duplicated_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e126831f-c423-4542-bd1f-53a9fe0b5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with only the first instances:\n",
      "        GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "60380    2484  1983-07-31    1983     3   10   INDL      C      D     STD   \n",
      "60381    2484  1983-10-31    1983     4   10   INDL      C      D     STD   \n",
      "60382    2484  1984-01-31    1984     1   10   INDL      C      D     STD   \n",
      "60383    2484  1984-04-30    1984     2   10   INDL      C      D     STD   \n",
      "60384    2484  1984-07-31    1984     3   10   INDL      C      D     STD   \n",
      "...       ...         ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "782060  30165  1999-06-30    1999     2   12   INDL      C      D     STD   \n",
      "782061  30165  1999-09-30    1999     3   12   INDL      C      D     STD   \n",
      "782062  30165  1999-12-31    1999     4   12   INDL      C      D     STD   \n",
      "782063  30165  2000-03-31    2000     1   12   INDL      C      D     STD   \n",
      "782064  30165  2000-06-30    2000     2   12   INDL      C      D     STD   \n",
      "\n",
      "          tic  ...  dvpq     ibq      lseq       ltq pstkq  teqq  txdbq  \\\n",
      "60380   0015B  ...   0.0   0.019   108.437    31.757   0.0   NaN    NaN   \n",
      "60381   0015B  ...   0.0   3.396   131.827    52.323   0.0   NaN    NaN   \n",
      "60382   0015B  ...   0.0  10.491   128.734    38.739   0.0   NaN    NaN   \n",
      "60383   0015B  ...   0.0   2.448   127.905    35.462   0.0   NaN    NaN   \n",
      "60384   0015B  ...   0.0   0.009   129.630    37.178   0.0   NaN    NaN   \n",
      "...       ...  ...   ...     ...       ...       ...   ...   ...    ...   \n",
      "782060   ZZZ1  ...   0.0  23.472  2511.398  1406.540   0.7   NaN    NaN   \n",
      "782061   ZZZ1  ...   0.0  29.707  2639.062  1526.796   0.7   NaN    NaN   \n",
      "782062   ZZZ1  ...   0.0  40.069  2905.644  1620.015   0.7   NaN    NaN   \n",
      "782063   ZZZ1  ...   0.0 -12.782  2792.078  1478.428   0.7   NaN    NaN   \n",
      "782064   ZZZ1  ...   0.0 -11.790  2979.502  1636.802   0.0   NaN    NaN   \n",
      "\n",
      "        costat      prccq  fyr_change_dummy  \n",
      "60380        I  33.999977                 0  \n",
      "60381        I  29.499977                 0  \n",
      "60382        I  19.749991                 0  \n",
      "60383        I  18.499990                 0  \n",
      "60384        I  16.999992                 0  \n",
      "...        ...        ...               ...  \n",
      "782060       A  52.000000                 0  \n",
      "782061       A  51.687500                 0  \n",
      "782062       A  52.125000                 0  \n",
      "782063       A  73.437500                 0  \n",
      "782064       A  75.875000                 0  \n",
      "\n",
      "[1075440 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['tic', 'fyearq', 'fqtr'], keep='first')\n",
    "\n",
    "print(\"DataFrame with only the first instances:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d76e9d-24f2-4c7d-934c-269209e2403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075440\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d838343c-c263-4388-8b47-b6b6ccafe2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085915"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1075440+20779-10304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af777d0-03b4-4e1d-9935-924d502d43a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial count of fyr_change_dummy = 1: 2139\n"
     ]
    }
   ],
   "source": [
    "initial_count = df['fyr_change_dummy'].sum()\n",
    "print(\"Initial count of fyr_change_dummy = 1:\", initial_count)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139cac8e-4bca-4bcc-a7cc-a12772e4c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagated DataFrame:\n",
      "         GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "0         2484  1983-07-31    1983     3   10   INDL      C      D     STD   \n",
      "1         2484  1983-10-31    1983     4   10   INDL      C      D     STD   \n",
      "2         2484  1984-01-31    1984     1   10   INDL      C      D     STD   \n",
      "3         2484  1984-04-30    1984     2   10   INDL      C      D     STD   \n",
      "4         2484  1984-07-31    1984     3   10   INDL      C      D     STD   \n",
      "...        ...         ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "1075435  30165  1999-06-30    1999     2   12   INDL      C      D     STD   \n",
      "1075436  30165  1999-09-30    1999     3   12   INDL      C      D     STD   \n",
      "1075437  30165  1999-12-31    1999     4   12   INDL      C      D     STD   \n",
      "1075438  30165  2000-03-31    2000     1   12   INDL      C      D     STD   \n",
      "1075439  30165  2000-06-30    2000     2   12   INDL      C      D     STD   \n",
      "\n",
      "           tic  ...  dvpq     ibq      lseq       ltq pstkq  teqq  txdbq  \\\n",
      "0        0015B  ...   0.0   0.019   108.437    31.757   0.0   NaN    NaN   \n",
      "1        0015B  ...   0.0   3.396   131.827    52.323   0.0   NaN    NaN   \n",
      "2        0015B  ...   0.0  10.491   128.734    38.739   0.0   NaN    NaN   \n",
      "3        0015B  ...   0.0   2.448   127.905    35.462   0.0   NaN    NaN   \n",
      "4        0015B  ...   0.0   0.009   129.630    37.178   0.0   NaN    NaN   \n",
      "...        ...  ...   ...     ...       ...       ...   ...   ...    ...   \n",
      "1075435   ZZZ1  ...   0.0  23.472  2511.398  1406.540   0.7   NaN    NaN   \n",
      "1075436   ZZZ1  ...   0.0  29.707  2639.062  1526.796   0.7   NaN    NaN   \n",
      "1075437   ZZZ1  ...   0.0  40.069  2905.644  1620.015   0.7   NaN    NaN   \n",
      "1075438   ZZZ1  ...   0.0 -12.782  2792.078  1478.428   0.7   NaN    NaN   \n",
      "1075439   ZZZ1  ...   0.0 -11.790  2979.502  1636.802   0.0   NaN    NaN   \n",
      "\n",
      "         costat      prccq  fyr_change_dummy  \n",
      "0             I  33.999977                 0  \n",
      "1             I  29.499977                 0  \n",
      "2             I  19.749991                 0  \n",
      "3             I  18.499990                 0  \n",
      "4             I  16.999992                 0  \n",
      "...         ...        ...               ...  \n",
      "1075435       A  52.000000                 0  \n",
      "1075436       A  51.687500                 0  \n",
      "1075437       A  52.125000                 0  \n",
      "1075438       A  73.437500                 0  \n",
      "1075439       A  75.875000                 0  \n",
      "\n",
      "[1075440 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "def propagate_fyr_change_dummy(df):\n",
    "    df_sorted = df.sort_values(by=['tic', 'fyearq', 'fqtr']).reset_index(drop=True)\n",
    "    updated_indices = set()  # To track indices that are updated\n",
    "    \n",
    "    for index, row in df_sorted.iterrows():\n",
    "        if row['fyr_change_dummy'] == 1:\n",
    "            tic = row['tic']\n",
    "            fyearq = row['fyearq']\n",
    "            fqtr = row['fqtr']\n",
    "            \n",
    "            # Propagate to next 3 quarters\n",
    "            for i in range(1, 4):\n",
    "                next_fyearq = fyearq + (fqtr + i - 1) // 4  # Calculate next fiscal year\n",
    "                next_fqtr = (fqtr + i - 1) % 4 + 1  # Calculate next quarter within the fiscal year\n",
    "                \n",
    "                # Find the index of the next quarter\n",
    "                next_row_idx = df_sorted.index[(df_sorted['tic'] == tic) & (df_sorted['fyearq'] == next_fyearq) & (df_sorted['fqtr'] == next_fqtr)]\n",
    "                \n",
    "                if len(next_row_idx) > 0 and next_row_idx[0] not in updated_indices:\n",
    "                    # Update fyr_change_dummy for the next quarter\n",
    "                    df_sorted.at[next_row_idx[0], 'fyr_change_dummy'] = 1\n",
    "                    updated_indices.add(next_row_idx[0])\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "# Apply the propagation functon\n",
    "df_propagated = propagate_fyr_change_dummy(df)\n",
    "df = df_propagated\n",
    "\n",
    "# Print the propagated DataFrame\n",
    "print(\"Propagated DataFrame:\")\n",
    "print(df_propagated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924fac96-c167-49a8-bea1-d8e5449eef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected max final count after propagation: 8556\n",
      "Actual final count after propagation: 8171\n"
     ]
    }
   ],
   "source": [
    "final_count = df_propagated['fyr_change_dummy'].sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Expected max final count after propagation:\", initial_count * 4)\n",
    "print(\"Actual final count after propagation:\", final_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddd8e288-3bc6-4edf-9132-a5cef7e5aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "0         2484  1983-07-31    1983     3   10   INDL      C      D     STD   \n",
      "1         2484  1983-10-31    1983     4   10   INDL      C      D     STD   \n",
      "2         2484  1984-01-31    1984     1   10   INDL      C      D     STD   \n",
      "3         2484  1984-04-30    1984     2   10   INDL      C      D     STD   \n",
      "4         2484  1984-07-31    1984     3   10   INDL      C      D     STD   \n",
      "...        ...         ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "1075435  30165  1999-06-30    1999     2   12   INDL      C      D     STD   \n",
      "1075436  30165  1999-09-30    1999     3   12   INDL      C      D     STD   \n",
      "1075437  30165  1999-12-31    1999     4   12   INDL      C      D     STD   \n",
      "1075438  30165  2000-03-31    2000     1   12   INDL      C      D     STD   \n",
      "1075439  30165  2000-06-30    2000     2   12   INDL      C      D     STD   \n",
      "\n",
      "           tic  ...  median_distance quarterly_median annual_median  \\\n",
      "0        0015B  ...              NaN              NaN           NaN   \n",
      "1        0015B  ...              NaN              NaN           NaN   \n",
      "2        0015B  ...              NaN              NaN           NaN   \n",
      "3        0015B  ...              NaN              NaN           NaN   \n",
      "4        0015B  ...              NaN              NaN           NaN   \n",
      "...        ...  ...              ...              ...           ...   \n",
      "1075435   ZZZ1  ...              NaN              NaN           NaN   \n",
      "1075436   ZZZ1  ...              NaN              NaN           NaN   \n",
      "1075437   ZZZ1  ...              NaN              NaN           NaN   \n",
      "1075438   ZZZ1  ...              NaN              NaN           NaN   \n",
      "1075439   ZZZ1  ...              NaN              NaN           NaN   \n",
      "\n",
      "        above_cshoq below_cshoq  above_datafqtr  below_datafqtr  diff_fqtr  \\\n",
      "0               NaN         NaN             NaN             NaN        NaN   \n",
      "1               NaN         NaN             NaN             NaN        NaN   \n",
      "2               NaN         NaN             NaN             NaN        NaN   \n",
      "3               NaN         NaN             NaN             NaN        NaN   \n",
      "4               NaN         NaN             NaN             NaN        NaN   \n",
      "...             ...         ...             ...             ...        ...   \n",
      "1075435         NaN         NaN             NaN             NaN        NaN   \n",
      "1075436         NaN         NaN             NaN             NaN        NaN   \n",
      "1075437         NaN         NaN             NaN             NaN        NaN   \n",
      "1075438         NaN         NaN             NaN             NaN        NaN   \n",
      "1075439         NaN         NaN             NaN             NaN        NaN   \n",
      "\n",
      "         diff_cshoq  new_cshoq  \n",
      "0               NaN        NaN  \n",
      "1               NaN        NaN  \n",
      "2               NaN        NaN  \n",
      "3               NaN        NaN  \n",
      "4               NaN        NaN  \n",
      "...             ...        ...  \n",
      "1075435         NaN        NaN  \n",
      "1075436         NaN        NaN  \n",
      "1075437         NaN        NaN  \n",
      "1075438         NaN        NaN  \n",
      "1075439         NaN        NaN  \n",
      "\n",
      "[1075440 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb8732-247e-4b4e-8b45-ad5e46f57e82",
   "metadata": {},
   "source": [
    "#### After we removed duplicated rows we ended up with 2139 fyr_change_dummy ==1. However, after propogation we can expect \n",
    "#### fyr change count up to 4*2139=8556, because each dummy might have up to 3 more consecutive values set to 1. But we have \n",
    "#### 8171 < 8556, which is reasonable, because first, we might miss some entries for some quarters, second, propagation might have \n",
    "#### affected the same quarters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18512c4-e544-4318-8a25-56e3c8778f20",
   "metadata": {},
   "source": [
    "#### We propagated fyr_change_dummy because when fyr change happens, alternative expeced date calculation method applies not to that quarter only but the following three quarters too. After which only we can use our regular expected date calculation method. While propogating we made sure there are no duplicate rows (taking first instances only) and we checked the number of missing either fyearq or/and, no such rows were found.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6696c261-f038-4c2b-93cb-3dc089deb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rdq'] = pd.to_datetime(df['rdq'], errors='coerce')\n",
    "df['fyearq'] = pd.to_numeric(df['fyearq'], errors='coerce')\n",
    "df['fqtr'] = pd.to_numeric(df['fqtr'], errors='coerce')\n",
    "\n",
    "grouped = df.groupby('tic', group_keys=False)\n",
    "\n",
    "# Function to calculate consecutive differences\n",
    "def calculate_diff(group):\n",
    "    # Sort the data within each group by the fiscal year and quarter in ascending order\n",
    "    group = group.sort_values(['fyearq', 'fqtr'])\n",
    "    \n",
    "    # Create a shifted column for the previous rdq\n",
    "    group['prev_rdq'] = group['rdq'].shift(1)\n",
    "    group['prev_fqtr'] = group['fqtr'].shift(1)\n",
    "    group['prev_fyearq'] = group['fyearq'].shift(1)\n",
    "    \n",
    "    # Calculate the differences\n",
    "    group['diff'] = group['rdq'] - group['prev_rdq']\n",
    "    \n",
    "    # Remove differences where quarters and years are not consecutive\n",
    "    mask = (group['fqtr'] == 1) & (group['prev_fqtr'] == 4) & (group['fyearq'] == group['prev_fyearq'] + 1)\n",
    "    mask |= (group['fqtr'] > 1) & (group['fqtr'] == group['prev_fqtr'] + 1) & (group['fyearq'] == group['prev_fyearq'])\n",
    "    \n",
    "    group['diff'] = group['diff'].where(mask)\n",
    "    \n",
    "    # Drop helper columns\n",
    "    group = group.drop(columns=['prev_rdq', 'prev_fqtr', 'prev_fyearq'])\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each ticker group directly in the original DataFrame\n",
    "df = grouped.apply(calculate_diff)\n",
    "df.loc[df['fyr_change_dummy'] == 1, 'diff'] = pd.NaT\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d278333-a352-4d67-aeb1-72a769395c97",
   "metadata": {},
   "source": [
    "#### Let's split the distance for quarterly and annual reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f136716d-dd72-4e64-a44f-5c98cd9f2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarterly_report'] = (df['fqtr'].isin([1, 2, 3])).astype(int)\n",
    "df['annual_report'] = (df['fqtr'] == 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ec9ae8-3d3d-4788-852d-9bda850b1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tic        rdq  fyr  fyearq  fqtr  fyr_change_dummy annual_distance  \\\n",
      "0  0015B        NaT   10    1983     3                 0             NaT   \n",
      "1  0015B 1984-01-16   10    1983     4                 0             NaT   \n",
      "2  0015B 1984-03-15   10    1984     1                 0             NaT   \n",
      "3  0015B 1984-05-25   10    1984     2                 0             NaT   \n",
      "4  0015B 1984-08-27   10    1984     3                 0             NaT   \n",
      "\n",
      "  quarter_distance    diff  \n",
      "0              NaT     NaT  \n",
      "1              NaT     NaT  \n",
      "2          59 days 59 days  \n",
      "3          71 days 71 days  \n",
      "4          94 days 94 days  \n"
     ]
    }
   ],
   "source": [
    "df['quarter_distance'] = df['diff'].where(df['quarterly_report'] == 1, pd.NaT)\n",
    "df['annual_distance'] = df['diff'].where(df['annual_report'] == 1, pd.NaT)\n",
    "print(df[['tic', 'rdq', 'fyr', 'fyearq', 'fqtr', 'fyr_change_dummy', 'annual_distance', 'quarter_distance', 'diff']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1232b5d7-8a3f-4da6-917e-2c02733ad77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'] = df['prccq'] / df['ajexq'] * df['cshoq']\n",
    "df['lower_bound'] = 0.8 * df['market_cap']\n",
    "df['upper_bound'] = 1.2 * df['market_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41947a1-2f8f-48cb-b7b2-f8e802ed93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with all empty distances: 1146\n",
      "Number of instances with non-empty distances: 7025\n",
      "Number of unique tickers with non-empty distances: 1499\n",
      "Number of unique tickers with all empty distances: 54\n",
      "Number of unique tickers with mixed distances: 417\n",
      "Total number of unique tickers with fiscal year changes: 1970\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the 'median_distance' column with NaN values\n",
    "df['median_distance'] = np.nan\n",
    "\n",
    "# Ensure the 'median_distance' column is updated for fiscal year change rows\n",
    "df['median_distance'] = np.where(df['fyr_change_dummy'] == 0, np.nan, df['median_distance'])\n",
    "\n",
    "# Initialize variables to count instances with all empty and non-empty distances\n",
    "num_instances_all_empty = 0\n",
    "num_instances_non_empty = 0\n",
    "\n",
    "# Initialize sets to store tickers with non-empty, empty, and mixed distances\n",
    "non_empty_distances_tickers = set()\n",
    "empty_distances_tickers = set()\n",
    "mixed_distances_tickers = set()\n",
    "\n",
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Determine if it's a quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Filter similar market cap tickers excluding own ticker\n",
    "    similar_cap_tickers = df[(df['market_cap'] >= fyr_change_row['lower_bound']) &\n",
    "                             (df['market_cap'] <= fyr_change_row['upper_bound']) &\n",
    "                             (df['tic'] != fyr_change_row['tic'])]\n",
    "\n",
    "    # Determine relevant distance column and filter criteria\n",
    "    distance_col = 'quarter_distance' if is_quarterly_report else 'annual_distance'\n",
    "    year_col = 'fyearq'\n",
    "    years = [fyr_change_row['fyearq'], fyr_change_row['fyearq'] + 1, fyr_change_row['fyearq'] - 1]\n",
    "\n",
    "    # Extract distances\n",
    "    distances = similar_cap_tickers[similar_cap_tickers[year_col].isin(years)][distance_col].dropna().apply(lambda x: pd.Timedelta(x).days)\n",
    "\n",
    "    # Check if distances list is empty\n",
    "    if distances.empty:\n",
    "        num_instances_all_empty += 1\n",
    "        if fyr_change_row['tic'] in non_empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "    else:\n",
    "        median_distance = distances.median()\n",
    "        df.loc[index, 'median_distance'] = median_distance\n",
    "        num_instances_non_empty += 1\n",
    "        if fyr_change_row['tic'] in empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            non_empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "\n",
    "# Calculate counts for unique tickers\n",
    "num_non_empty_distances_tickers = len(non_empty_distances_tickers - mixed_distances_tickers)\n",
    "num_empty_distances_tickers = len(empty_distances_tickers - mixed_distances_tickers)\n",
    "num_mixed_distances_tickers = len(mixed_distances_tickers)\n",
    "num_unique_fyr_change_tickers = fyr_change_rows['tic'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of instances with all empty distances: {num_instances_all_empty}\")\n",
    "print(f\"Number of instances with non-empty distances: {num_instances_non_empty}\")\n",
    "print(f\"Number of unique tickers with non-empty distances: {num_non_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with all empty distances: {num_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with mixed distances: {num_mixed_distances_tickers}\")\n",
    "print(f\"Total number of unique tickers with fiscal year changes: {num_unique_fyr_change_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bfbe9-16dc-4d3d-a44f-7d279e36ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dd07ef7-dd0d-4855-adfe-7f3cf61b72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Check if fiscal year change happened in quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Determine which column to assign median distance\n",
    "    median_distance_column = 'annual_median' if not is_quarterly_report else 'quarterly_median'\n",
    "\n",
    "    # Update the median_distance column accordingly\n",
    "    df.loc[index, median_distance_column] = fyr_change_row['median_distance']\n",
    "\n",
    "# Set NaN for rows where fyr_change_dummy is 0\n",
    "df.loc[df['fyr_change_dummy'] == 0, ['annual_median', 'quarterly_median']] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b3063c-c983-4a40-a08e-41c164d30749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7025.00\n",
      "mean       96.12\n",
      "std        11.27\n",
      "min        38.00\n",
      "25%        90.00\n",
      "50%        91.00\n",
      "75%       102.00\n",
      "max       156.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1102b-a6c5-4fd2-9577-45cefc8bd9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d878b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7025.00\n",
      "mean       96.12\n",
      "std        11.27\n",
      "min        38.00\n",
      "25%        90.00\n",
      "50%        91.00\n",
      "75%       102.00\n",
      "max       156.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c0d373-272a-417a-baea-05d8c41dae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for Annual Median:\n",
      "count    1899.000000\n",
      "mean      112.913902\n",
      "std         8.588462\n",
      "min        98.000000\n",
      "25%       106.000000\n",
      "50%       112.000000\n",
      "75%       119.000000\n",
      "max       156.000000\n",
      "Name: annual_median, dtype: float64\n",
      "\n",
      "Summary statistixcs for Quarterly Median:\n",
      "count    5126.000000\n",
      "mean       89.891728\n",
      "std         1.859526\n",
      "min        38.000000\n",
      "25%        90.000000\n",
      "50%        90.000000\n",
      "75%        91.000000\n",
      "max        96.000000\n",
      "Name: quarterly_median, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annual_median_summary = df['annual_median'].describe()\n",
    "print(\"Summary statistics for Annual Median:\")\n",
    "print(annual_median_summary)\n",
    "\n",
    "quarterly_median_summary = df['quarterly_median'].describe()\n",
    "print(\"\\nSummary statistixcs for Quarterly Median:\")\n",
    "print(quarterly_median_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ee9f0-7aae-4128-a9b3-b09a076c98ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59c9b9f5-78ec-4685-9222-a870744dd202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7025.00\n",
      "mean       96.12\n",
      "std        11.27\n",
      "min        38.00\n",
      "25%        90.00\n",
      "50%        91.00\n",
      "75%       102.00\n",
      "max       156.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55886d84-a06d-4f99-959e-e4f1d7fba394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'] = df['prccq'] / df['ajexq'] * df['cshoq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b25cb724-4051-4478-8311-65bdebb8d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower bounds\n",
    "df['lower_bound'] = 0.8 * df['market_cap']\n",
    "df['upper_bound'] = 1.2 * df['market_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "672f6241-33c8-49ae-8280-ce6b80b94c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarterly_report'] = (df['fqtr'].isin([1, 2, 3])).astype(int)\n",
    "df['annual_report'] = (df['fqtr'] == 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9905736-5d79-4752-8b0f-607ebfde13e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries where fyr_change_dummy == 1 and market_cap is empty: 1139\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & (df['market_cap'].isna())]\n",
    "num_entries = len(filtered_df)\n",
    "\n",
    "print(f'Number of entries where fyr_change_dummy == 1 and market_cap is empty: {num_entries}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b8061-8f86-4369-b0ad-5607dfde97a0",
   "metadata": {},
   "source": [
    "#### As we see instances which had fyr change, 1139 cases had empty market_caps. It means 1139 out of 1146 median distances that \n",
    "#### are uncalculated was due to **missing market_cap**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d492cc5-0a86-4cf1-88fe-731c7ea1beab",
   "metadata": {},
   "source": [
    "#### We will find cshoq to be proportional value between its last and next reported values, otherwise it is reasonable that we can't calculate median distances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11a61c0c-8e45-46f8-9034-7d74d7ecdd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries where fyr_change_dummy == 1 and cshoq is empty: 1071\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & (df['cshoq'].isna())]\n",
    "num_entries = len(filtered_df)\n",
    "\n",
    "print(f'Number of entries where fyr_change_dummy == 1 and cshoq is empty: {num_entries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c83aeab-248f-4067-b2a3-2a28f091a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with fiscal year change and 'prccq' missing: 97\n"
     ]
    }
   ],
   "source": [
    "filtered_rows = df[(df['fyr_change_dummy'] == 1) & df['prccq'].isna()]\n",
    "print(f\"Number of rows with fiscal year change and 'prccq' missing: {len(filtered_rows)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c49735c-3346-4677-8ac1-bbfeec97963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with fiscal year change and both 'cshoq', 'prccq' missing: 0\n"
     ]
    }
   ],
   "source": [
    "fr = df[(df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['prccq'].isna() ]\n",
    "print(f\"Number of rows with fiscal year change and both 'cshoq', 'prccq' missing: {len(fr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e01f43-cab4-4eef-aff3-403802558441",
   "metadata": {},
   "source": [
    "#### 1139 of missing market_cap, out of which 1071 is due to cshoq absence, 97 is from price 'prccq' absense. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a42c20-9f5c-491d-8023-bc946609a331",
   "metadata": {},
   "source": [
    "#### For now we will relieve this 97 missing price cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ed3a2-ef2c-4f2c-ad51-ca177ebe6de0",
   "metadata": {},
   "source": [
    "#### Now we will look for one above and below non-empty 'cshoq'. Determining which year and quarter found cshoqs belong to, we calculate the proportionate cshoq where it's missing\n",
    "#### Example: Missing cshoq is 2024 Q1, above non-empty cshoq 2023 Q4 = 7, below 2024 Q2 =8, then we fill in with 7.5\n",
    "#### Missing cshoq is 2024 Q2, above non-empty cshoq 2024 Q2 = 1, below 2024 Q4 =2, then we fill in with 1.33. \n",
    "#### If above and below non-empty cshoqs are the same, then our cshoq is equal to that value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aecd4b19-abfc-4232-afb5-a179672506c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_7432\\4092613696.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1988Q4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'above_datafqtr'] = above_row['datafqtr']\n",
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_7432\\4092613696.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1989Q4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'below_datafqtr'] = below_row['datafqtr']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GVKEY    datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "22        2484  1988-09-30    1989     1    6   INDL      C      D     STD   \n",
      "23        2484  1988-12-31    1989     2    6   INDL      C      D     STD   \n",
      "24        2484  1989-03-31    1989     3    6   INDL      C      D     STD   \n",
      "1035     23929  1996-12-31    1997     1    9   INDL      C      D     STD   \n",
      "2910      6726  1979-12-31    1980     1    9   INDL      C      D     STD   \n",
      "...        ...         ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "1069738  11656  1991-05-31    1991     1    2   INDL      C      D     STD   \n",
      "1069739  11656  1991-08-31    1991     2    2   INDL      C      D     STD   \n",
      "1073140  11669  1994-01-31    1994     2    7   INDL      C      D     STD   \n",
      "1073141  11669  1994-04-30    1994     3    7   INDL      C      D     STD   \n",
      "1074392  11310  1991-06-30    1991     4    6   INDL      C      D     STD   \n",
      "\n",
      "           tic  ...  market_cap lower_bound upper_bound median_distance  \\\n",
      "22       0015B  ...         NaN         NaN         NaN             NaN   \n",
      "23       0015B  ...         NaN         NaN         NaN             NaN   \n",
      "24       0015B  ...         NaN         NaN         NaN             NaN   \n",
      "1035     0147A  ...         NaN         NaN         NaN             NaN   \n",
      "2910     2788A  ...         NaN         NaN         NaN             NaN   \n",
      "...        ...  ...         ...         ...         ...             ...   \n",
      "1069738   YORK  ...         NaN         NaN         NaN             NaN   \n",
      "1069739   YORK  ...         NaN         NaN         NaN             NaN   \n",
      "1073140    ZLC  ...         NaN         NaN         NaN             NaN   \n",
      "1073141    ZLC  ...         NaN         NaN         NaN             NaN   \n",
      "1074392   ZRBA  ...         NaN         NaN         NaN             NaN   \n",
      "\n",
      "        quarterly_median  annual_median  above_cshoq  below_cshoq  \\\n",
      "22                   NaN            NaN       11.762       11.808   \n",
      "23                   NaN            NaN       11.762       11.808   \n",
      "24                   NaN            NaN       11.762       11.808   \n",
      "1035                 NaN            NaN        6.548        6.555   \n",
      "2910                 NaN            NaN        8.436        8.458   \n",
      "...                  ...            ...          ...          ...   \n",
      "1069738              NaN            NaN        8.477        9.148   \n",
      "1069739              NaN            NaN        8.477        9.148   \n",
      "1073140              NaN            NaN       34.965       34.965   \n",
      "1073141              NaN            NaN       34.965       34.965   \n",
      "1074392              NaN            NaN        1.454        1.454   \n",
      "\n",
      "         above_datafqtr  below_datafqtr  \n",
      "22               1988Q4          1989Q4  \n",
      "23               1988Q4          1989Q4  \n",
      "24               1988Q4          1989Q4  \n",
      "1035             1996Q4          1997Q2  \n",
      "2910             1979Q4          1980Q2  \n",
      "...                 ...             ...  \n",
      "1069738          1990Q4          1991Q3  \n",
      "1069739          1990Q4          1991Q3  \n",
      "1073140          1994Q1          1994Q4  \n",
      "1073141          1994Q1          1994Q4  \n",
      "1074392          1991Q3          1992Q1  \n",
      "\n",
      "[1071 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize above_cshoq, below_cshoq, above_datafqtr, and below_datafqtr as NaN\n",
    "df['above_cshoq'] = np.nan\n",
    "df['below_cshoq'] = np.nan\n",
    "df['above_datafqtr'] = np.nan\n",
    "df['below_datafqtr'] = np.nan\n",
    "\n",
    "# Find rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "missing_cshoq_indices = df[(df['fyr_change_dummy'] == 1) & df['cshoq'].isna()].index\n",
    "\n",
    "# Iterate over the missing cshoq indices to find above_cshoq, below_cshoq, above_datafqtr, and below_datafqtr\n",
    "for index in missing_cshoq_indices:\n",
    "    tic = df.at[index, 'tic']\n",
    "    current_datafqtr = df.at[index, 'datafqtr']\n",
    "    \n",
    "    # Find the row above with a non-missing cshoq value\n",
    "    above_rows = df[(df['tic'] == tic) & (df['datafqtr'] < current_datafqtr)].sort_values(by='datafqtr', ascending=False)\n",
    "    for _, above_row in above_rows.iterrows():\n",
    "        if not pd.isna(above_row['cshoq']):\n",
    "            df.at[index, 'above_cshoq'] = above_row['cshoq']\n",
    "            df.at[index, 'above_datafqtr'] = above_row['datafqtr']\n",
    "            break\n",
    "    \n",
    "    # Find the row below with a non-missing cshoq value\n",
    "    below_rows = df[(df['tic'] == tic) & (df['datafqtr'] > current_datafqtr)].sort_values(by='datafqtr', ascending=True)\n",
    "    for _, below_row in below_rows.iterrows():\n",
    "        if not pd.isna(below_row['cshoq']):\n",
    "            df.at[index, 'below_cshoq'] = below_row['cshoq']\n",
    "            df.at[index, 'below_datafqtr'] = below_row['datafqtr']\n",
    "            break\n",
    "\n",
    "# Print rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "print(df[(df['fyr_change_dummy'] == 1) & df['cshoq'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8207186e-a5be-4a69-9365-faec3245b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where both above_cshoq and below_cshoq are not  NaN: 1017\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['above_cshoq'].notna() & \n",
    "                 df['below_cshoq'].notna()]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where both above_cshoq and below_cshoq are not  NaN:\", count_both_na)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2f5c220-dde8-4f38-ba77-abf023e47f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_fqtr'] = np.nan\n",
    "\n",
    "# Calculate diff_fqtr for rows where both below_datafqtr and above_datafqtr are given\n",
    "mask = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['below_datafqtr'].notna() & df['above_datafqtr'].notna()\n",
    "\n",
    "for index, row in df[mask].iterrows():\n",
    "    # Extract year and quarter from below_datafqtr and above_datafqtr\n",
    "    below_year, below_quarter = row['below_datafqtr'].split('Q')\n",
    "    above_year, above_quarter = row['above_datafqtr'].split('Q')\n",
    "\n",
    "    # Convert year and quarter to integers\n",
    "    below_year = int(below_year)\n",
    "    below_quarter = int(below_quarter)\n",
    "    above_year = int(above_year)\n",
    "    above_quarter = int(above_quarter)\n",
    "\n",
    "    # Calculate the difference in quarters\n",
    "    diff_fqtr = (below_year - above_year) * 4 + (below_quarter - above_quarter)\n",
    "\n",
    "    # Update the diff_fqtr column with the calculated difference\n",
    "    df.at[index, 'diff_fqtr'] = diff_fqtr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a529b0-cbf7-4ec5-8f59-fc3ca633a62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_fqtr are  NaN: 54\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_fqtr'].isna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_fqtr are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d99f5cd7-af1b-4047-a2a8-0804a8d20876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_cshoq'] = df.apply(lambda row: row['below_cshoq'] - row['above_cshoq'] if pd.notna(row['above_cshoq']) and pd.notna(row['below_cshoq']) else np.nan, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc9bcc4-c97b-41a1-8c7e-448de4628c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_cshoq are  NaN: 54\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_cshoq'].isna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_cshoq are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4370a1bd-fece-4be4-b136-a18fad010f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where noth above_datafqtr and below_datafqtr are  NaN: 3\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['above_datafqtr'].isna() &df['below_datafqtr'].isna()   ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where noth above_datafqtr and below_datafqtr are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "890fd244-c25a-474c-8d71-88c71ba5f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tic  fyr  fqtr   cshoq      prccq     ajexq\n",
      "76626  CHLN.1   12     1  12.076   7.860000  1.000000\n",
      "76627  CHLN.1   12     2  12.076   7.700000  1.000000\n",
      "76628  CHLN.1   12     3  12.078   7.841000  1.000000\n",
      "76629  CHLN.1   12     4  12.076   8.800000  1.000000\n",
      "76630  CHLN.1   12     1  12.083   9.000000  1.000000\n",
      "76631  CHLN.1   12     2  12.096  10.880000  1.000000\n",
      "76632  CHLN.1   12     3  13.478  10.500000  1.000000\n",
      "76633   CHAM.    6     4     NaN   6.250000  1.049999\n",
      "76634   CHAM.    3     1     NaN   8.999999  1.049999\n",
      "76635   CHAM.    3     2     NaN   9.249999  1.049999\n",
      "76636   CHAM.    3     3     NaN  10.624999  1.049999\n",
      "76637   CJHBQ    2     2  34.907   3.750000  0.800000\n",
      "76638   CJHBQ    2     3  34.903   3.500000  0.800000\n",
      "76639   CJHBQ    2     4  35.003   5.875000  0.800000\n",
      "76640   CJHBQ    2     1  35.003   4.125000  0.800000\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('/Users/balmeru/Downloads/QQQQ.csv')\n",
    "\n",
    "# Slice the DataFrame to extract rows 76626 to 76640\n",
    "df_subset = df_original.iloc[76626:76641][['tic', 'fyr', 'fqtr', 'cshoq', 'prccq', 'ajexq']]\n",
    "\n",
    "print(df_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e58f41b-c2c3-4e4a-895d-55fa9fb98770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_cshoq are not  NaN: 1017\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna() & \n",
    "                 df['diff_cshoq'].notna() ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where diff_cshoq are not  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "345ad09e-c2fe-426a-80d4-c42c4447a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tic  fyr  cshoq  above_cshoq  new_cshoq\n",
      "22       0015B    6    NaN       11.762  11.773500\n",
      "23       0015B    6    NaN       11.762  11.785000\n",
      "24       0015B    6    NaN       11.762  11.796500\n",
      "1035     0147A    9    NaN        6.548   6.551500\n",
      "2910     2788A    9    NaN        8.436   8.447000\n",
      "...        ...  ...    ...          ...        ...\n",
      "1069738   YORK    2    NaN        8.477   8.700667\n",
      "1069739   YORK    2    NaN        8.477   8.924333\n",
      "1073140    ZLC    7    NaN       34.965  34.965000\n",
      "1073141    ZLC    7    NaN       34.965  34.965000\n",
      "1074392   ZRBA    6    NaN        1.454   1.454000\n",
      "\n",
      "[1017 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['new_cshoq'] = np.nan\n",
    "\n",
    "# Calculate new_cshoq for rows where fyr_change_dummy is 1, cshoq is NaN, and diff_cshoq and diff_fqtr are not NaN\n",
    "mask = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['diff_cshoq'].notna() & df['diff_fqtr'].notna()\n",
    "\n",
    "for index, row in df[mask].iterrows():\n",
    "    # Calculate the difference between datafqtr and above_datafqtr\n",
    "    above_year, above_quarter = row['above_datafqtr'].split('Q')\n",
    "    data_year, data_quarter = row['datafqtr'].split('Q')\n",
    "    \n",
    "    above_year = int(above_year)\n",
    "    above_quarter = int(above_quarter)\n",
    "    data_year = int(data_year)\n",
    "    data_quarter = int(data_quarter)\n",
    "    \n",
    "    difference = (data_year - above_year) * 4 + (data_quarter - above_quarter)\n",
    "    \n",
    "    # Calculate new_cshoq value\n",
    "    new_cshoq = row['above_cshoq'] + (row['diff_cshoq'] / row['diff_fqtr']) * difference\n",
    "    \n",
    "    # Update the new_cshoq column with the calculated value\n",
    "    df.at[index, 'new_cshoq'] = new_cshoq\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq', 'above_cshoq', 'new_cshoq']][mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb3dd10e-6dfb-44e5-ba25-2947bd130da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tic  fyr  cshoq  above_cshoq  below_cshoq  new_cshoq\n",
      "4682      3ACDX   12    NaN        2.100          NaN      2.100\n",
      "9713      3BPCO   12    NaN       21.163          NaN     21.163\n",
      "9714      3BPCO   12    NaN       21.163          NaN     21.163\n",
      "37211    3STPHF    9    NaN        3.969          NaN      3.969\n",
      "51136     5841A    9    NaN       85.800          NaN     85.800\n",
      "51359     5853B    6    NaN        2.669          NaN      2.669\n",
      "51360     5853B    6    NaN        2.669          NaN      2.669\n",
      "52393     6033B    7    NaN        7.194          NaN      7.194\n",
      "53626     6103B   12    NaN        3.416          NaN      3.416\n",
      "55279     6733B    1    NaN        8.987          NaN      8.987\n",
      "57425     7556A    6    NaN       16.111          NaN     16.111\n",
      "57426     7556A    6    NaN       16.111          NaN     16.111\n",
      "58521     8550B   12    NaN       56.286          NaN     56.286\n",
      "58522     8550B   12    NaN       56.286          NaN     56.286\n",
      "60280     9901B    8    NaN       15.764          NaN     15.764\n",
      "60281     9901B    8    NaN       15.764          NaN     15.764\n",
      "60282     9901B    8    NaN       15.764          NaN     15.764\n",
      "77694     ADVT.   12    NaN       13.078          NaN     13.078\n",
      "84267       AG1   12    NaN       15.096          NaN     15.096\n",
      "101563   AMAG.2    7    NaN       11.095          NaN     11.095\n",
      "235287    CGA.1   12    NaN          NaN      312.110    312.110\n",
      "235288    CGA.1   12    NaN          NaN      312.110    312.110\n",
      "235289    CGA.1   12    NaN          NaN      312.110    312.110\n",
      "236731     CGNE   12    NaN       60.443          NaN     60.443\n",
      "237719    CHAM.    3    NaN          NaN          NaN        NaN\n",
      "237720    CHAM.    3    NaN          NaN          NaN        NaN\n",
      "237721    CHAM.    3    NaN          NaN          NaN        NaN\n",
      "243981    CHZ.1   12    NaN       17.651          NaN     17.651\n",
      "259444     CMRK   12    NaN       23.153          NaN     23.153\n",
      "283447    CRTCF   12    NaN       12.779          NaN     12.779\n",
      "283448    CRTCF   12    NaN       12.779          NaN     12.779\n",
      "283449    CRTCF   12    NaN       12.779          NaN     12.779\n",
      "336261    DTGLF   12    NaN       18.341          NaN     18.341\n",
      "336262    DTGLF   12    NaN       18.341          NaN     18.341\n",
      "387236      FA1    6    NaN       25.075          NaN     25.075\n",
      "387237      FA1    6    NaN       25.075          NaN     25.075\n",
      "387238      FA1    6    NaN       25.075          NaN     25.075\n",
      "418592    FPFXQ   12    NaN       42.093          NaN     42.093\n",
      "481385      HFO    9    NaN        0.977          NaN      0.977\n",
      "481386      HFO    9    NaN        0.977          NaN      0.977\n",
      "585688    LCNAF    9    NaN       24.731          NaN     24.731\n",
      "585689    LCNAF    9    NaN       24.731          NaN     24.731\n",
      "585812    LCOR.    9    NaN        1.358          NaN      1.358\n",
      "610870     LXUH    6    NaN        2.885          NaN      2.885\n",
      "626100     MDCA   12    NaN          NaN       12.353     12.353\n",
      "626101     MDCA   12    NaN          NaN       12.353     12.353\n",
      "626102     MDCA   12    NaN          NaN       12.353     12.353\n",
      "680869     NAB1    9    NaN       43.473          NaN     43.473\n",
      "804775     PTLX    6    NaN        2.527          NaN      2.527\n",
      "894340    SMTQQ    9    NaN        5.902          NaN      5.902\n",
      "993294    UDS.2    5    NaN        0.965          NaN      0.965\n",
      "993295    UDS.2    5    NaN        0.965          NaN      0.965\n",
      "1017065   VGR.1   12    NaN       19.880          NaN     19.880\n",
      "1064901     XLL   12    NaN      104.860          NaN    104.860\n"
     ]
    }
   ],
   "source": [
    "# Update new_cshoq for rows where fyr_change_dummy is 1, cshoq is NaN, and above_cshoq or below_cshoq is NaN\n",
    "mask_above_nan = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['above_cshoq'].isna()\n",
    "mask_below_nan = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna() & df['below_cshoq'].isna()\n",
    "\n",
    "# Set new_cshoq equal to below_cshoq when above_cshoq is NaN\n",
    "df.loc[mask_above_nan, 'new_cshoq'] = df.loc[mask_above_nan, 'below_cshoq']\n",
    "\n",
    "# Set new_cshoq equal to above_cshoq when below_cshoq is NaN\n",
    "df.loc[mask_below_nan, 'new_cshoq'] = df.loc[mask_below_nan, 'above_cshoq']\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq', 'above_cshoq', 'below_cshoq', 'new_cshoq']][mask_above_nan | mask_below_nan])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc42737-7b38-4234-a9ca-844c348e1a7a",
   "metadata": {},
   "source": [
    "### IMPORTANT: I filled in with above or below cshoq wherever either of them was missing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25340a16-5779-4815-a2df-aa98d8699a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33967d-05d9-4a41-bdea-84a32836501a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "847054eb-d4f9-4e3a-866e-ca679b2768d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tic  fyr      cshoq\n",
      "22       0015B    6  11.773500\n",
      "23       0015B    6  11.785000\n",
      "24       0015B    6  11.796500\n",
      "1035     0147A    9   6.551500\n",
      "2910     2788A    9   8.447000\n",
      "...        ...  ...        ...\n",
      "1069738   YORK    2   8.700667\n",
      "1069739   YORK    2   8.924333\n",
      "1073140    ZLC    7  34.965000\n",
      "1073141    ZLC    7  34.965000\n",
      "1074392   ZRBA    6   1.454000\n",
      "\n",
      "[1071 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace original cshoq values with new_cshoq for rows where fyr_change_dummy is 1 and cshoq is NaN\n",
    "mask_replace_cshoq = (df['fyr_change_dummy'] == 1) & df['cshoq'].isna()\n",
    "\n",
    "# Update cshoq with new_cshoq values\n",
    "df.loc[mask_replace_cshoq, 'cshoq'] = df.loc[mask_replace_cshoq, 'new_cshoq']\n",
    "\n",
    "print(df[['tic', 'fyr', 'cshoq']][mask_replace_cshoq])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c15b397-2b9b-443e-83ec-b4749ab008c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where diff_fqtr are  NaN: 3\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & \n",
    "                 df['cshoq'].isna()  ]\n",
    "count_both_na = filtered_df.shape[0]\n",
    "print(\"Number of rows where cshoq are  NaN:\", count_both_na)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf17b9b-73cd-427c-b987-76eea38b2081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ad212-3833-4066-a458-b0baa5da7929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a6a297e-4c81-4176-bae0-69c56650d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'] = df['prccq'] / df['ajexq'] * df['cshoq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fadd98e-110a-4208-89ac-c127b4d4cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower bounds\n",
    "df['lower_bound'] = 0.8 * df['market_cap']\n",
    "df['upper_bound'] = 1.2 * df['market_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cc7f980-842f-4843-9935-b34bc6324a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarterly_report'] = (df['fqtr'].isin([1, 2, 3])).astype(int)\n",
    "df['annual_report'] = (df['fqtr'] == 4).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0abedaaf-7ed5-4f32-8ecf-64fc3a872897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with all empty distances: 108\n",
      "Number of instances with non-empty distances: 8063\n",
      "Number of unique tickers with non-empty distances: 1932\n",
      "Number of unique tickers with all empty distances: 9\n",
      "Number of unique tickers with mixed distances: 29\n",
      "Total number of unique tickers with fiscal year changes: 1970\n"
     ]
    }
   ],
   "source": [
    "df['median_distance'] = np.nan\n",
    "\n",
    "# Ensure the 'median_distance' column is updated for fiscal year change rows\n",
    "df['median_distance'] = np.where(df['fyr_change_dummy'] == 0, np.nan, df['median_distance'])\n",
    "\n",
    "# Initialize variables to count instances with all empty and non-empty distances\n",
    "num_instances_all_empty = 0\n",
    "num_instances_non_empty = 0\n",
    "\n",
    "# Initialize sets to store tickers with non-empty, empty, and mixed distances\n",
    "non_empty_distances_tickers = set()\n",
    "empty_distances_tickers = set()\n",
    "mixed_distances_tickers = set()\n",
    "\n",
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Determine if it's a quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Filter similar market cap tickers excluding own ticker\n",
    "    similar_cap_tickers = df[(df['market_cap'] >= fyr_change_row['lower_bound']) &\n",
    "                             (df['market_cap'] <= fyr_change_row['upper_bound']) &\n",
    "                             (df['tic'] != fyr_change_row['tic'])]\n",
    "\n",
    "    # Determine relevant distance column and filter criteria\n",
    "    distance_col = 'quarter_distance' if is_quarterly_report else 'annual_distance'\n",
    "    year_col = 'fyearq'\n",
    "    years = [fyr_change_row['fyearq'], fyr_change_row['fyearq'] + 1, fyr_change_row['fyearq'] - 1]\n",
    "\n",
    "    # Extract distances\n",
    "    distances = similar_cap_tickers[similar_cap_tickers[year_col].isin(years)][distance_col].dropna().apply(lambda x: pd.Timedelta(x).days)\n",
    "\n",
    "    # Check if distances list is empty\n",
    "    if distances.empty:\n",
    "        num_instances_all_empty += 1\n",
    "        if fyr_change_row['tic'] in non_empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "    else:\n",
    "        median_distance = distances.median()\n",
    "        df.loc[index, 'median_distance'] = median_distance\n",
    "        num_instances_non_empty += 1\n",
    "        if fyr_change_row['tic'] in empty_distances_tickers:\n",
    "            mixed_distances_tickers.add(fyr_change_row['tic'])\n",
    "        else:\n",
    "            non_empty_distances_tickers.add(fyr_change_row['tic'])\n",
    "\n",
    "# Calculate counts for unique tickers\n",
    "num_non_empty_distances_tickers = len(non_empty_distances_tickers - mixed_distances_tickers)\n",
    "num_empty_distances_tickers = len(empty_distances_tickers - mixed_distances_tickers)\n",
    "num_mixed_distances_tickers = len(mixed_distances_tickers)\n",
    "num_unique_fyr_change_tickers = fyr_change_rows['tic'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of instances with all empty distances: {num_instances_all_empty}\")\n",
    "print(f\"Number of instances with non-empty distances: {num_instances_non_empty}\")\n",
    "print(f\"Number of unique tickers with non-empty distances: {num_non_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with all empty distances: {num_empty_distances_tickers}\")\n",
    "print(f\"Number of unique tickers with mixed distances: {num_mixed_distances_tickers}\")\n",
    "print(f\"Total number of unique tickers with fiscal year changes: {num_unique_fyr_change_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fce880-509a-4002-b347-a0e4099e621e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c98f758a-9650-4842-a107-5d7b8a8497f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8063.00\n",
      "mean       95.46\n",
      "std        10.85\n",
      "min        38.00\n",
      "25%        90.00\n",
      "50%        90.00\n",
      "75%        91.00\n",
      "max       156.00\n",
      "Name: median_distance, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['median_distance'].describe()\n",
    "formatted_stats = summary_stats.apply(lambda x: f'{x:.2f}')\n",
    "\n",
    "print(formatted_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806ef25-0959-4153-a212-a540b3ae0527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f899554-1268-4876-a143-41dc89375f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where fiscal year change occurred\n",
    "fyr_change_rows = df[df['fyr_change_dummy'] == 1]\n",
    "\n",
    "# Iterate over rows where fiscal year change occurred\n",
    "for index, fyr_change_row in fyr_change_rows.iterrows():\n",
    "    # Check if fiscal year change happened in quarterly or annual report\n",
    "    is_quarterly_report = fyr_change_row['quarterly_report'] == 1\n",
    "\n",
    "    # Determine which column to assign median distance\n",
    "    median_distance_column = 'annual_median' if not is_quarterly_report else 'quarterly_median'\n",
    "\n",
    "    # Update the median_distance column accordingly\n",
    "    df.loc[index, median_distance_column] = fyr_change_row['median_distance']\n",
    "\n",
    "# Set NaN for rows where fyr_change_dummy is 0\n",
    "df.loc[df['fyr_change_dummy'] == 0, ['annual_median', 'quarterly_median']] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ac2d930-b0a9-4eea-b52b-68b318917271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for Annual Median:\n",
      "count    1954.000000\n",
      "mean      112.930911\n",
      "std         8.585022\n",
      "min        98.000000\n",
      "25%       106.000000\n",
      "50%       112.000000\n",
      "75%       119.000000\n",
      "max       156.000000\n",
      "Name: annual_median, dtype: float64\n",
      "\n",
      "Summary statistixcs for Quarterly Median:\n",
      "count    6109.000000\n",
      "mean       89.872974\n",
      "std         1.756219\n",
      "min        38.000000\n",
      "25%        89.000000\n",
      "50%        90.000000\n",
      "75%        91.000000\n",
      "max        96.000000\n",
      "Name: quarterly_median, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annual_median_summary = df['annual_median'].describe()\n",
    "print(\"Summary statistics for Annual Median:\")\n",
    "print(annual_median_summary)\n",
    "\n",
    "quarterly_median_summary = df['quarterly_median'].describe()\n",
    "print(\"\\nSummary statistixcs for Quarterly Median:\")\n",
    "print(quarterly_median_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882d3e5-345e-434f-b6a4-e3dc11dea765",
   "metadata": {},
   "source": [
    "#### Overall we have 8171 cases with fyr change. We calculated median distances for 8063 cases. \n",
    "#### 1139 out of 1146 median distances was due to missing market cap. \n",
    "#### 97 cases didn't have prccq when fyr_change_dummy == 1, thus didn't have market cap to be calculated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5eabc50f-0b25-4174-8d9e-95c8af60ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "filtered_df = df[(df['fyr_change_dummy'] == 1) & df['prccq'].isna()]\n",
    "\n",
    "# Select the specific columns\n",
    "filtered_columns_df = filtered_df[['tic', 'fyr', 'fqtr', 'cshoq', 'prccq', 'ajexq']]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(len(filtered_columns_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0284738-7924-4abc-b9ec-e301ed945e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rows have been saved to 'with_median_distances.csv'.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('/Users/balmeru/Downloads/with_median_distances.csv', index=False)\n",
    "\n",
    "print(\"Selected rows have been saved to 'with_median_distances.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc644b3c-0109-4ac0-8356-3905ecbe5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame (using shape): 1075440\n"
     ]
    }
   ],
   "source": [
    "num_rows_shape = df.shape[0]\n",
    "print(f\"Number of rows in the DataFrame (using shape): {num_rows_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2baae01-7b2f-4827-9d96-a4ea116d006e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469372b-3dd4-4ae1-ad3c-97a7d0ae26b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6528b-7233-4fc0-8f7d-248155815862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3df9b-7dac-4dbd-a83d-8f178272ad90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f30a14-3093-4335-914d-e696c0c9e38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c66bfa-1383-4f5d-9f54-5dcef462a357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de304c72-2a44-406c-8039-07e44c464fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f26bb6-1547-4231-b8e9-a35518809413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496915d-3671-4dfa-9b59-9637d2194a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a4be4-a2c2-475e-bec7-e2c7ae5b5f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b57368-0a00-4379-af03-59a4140c995e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f619f69-c0e3-48df-892e-2159311c0f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dfab6-ea42-4beb-8841-57da30dae663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864a7d0-07b4-4f0d-ba86-b3bba5a64fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d5428-3551-493f-8b4a-53391a324aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659240f-c9f0-47e7-bca3-efee5b40c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
