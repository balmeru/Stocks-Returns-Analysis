{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a323619-4822-4764-bdd6-efce93ca54a4",
   "metadata": {},
   "source": [
    "#### We ensure that each weekly return pivot has eindxes - Monday dates and that the returns are for full week days. Example, 31st Dec is Monday in 1984. However, that week contains 4 other days from 1985, so we have weky return for the Monday 31st Dec 1984 in pivot 1985. Thus, we remove that row from 1984 and keep 1985, as full weekly return only correctly presented in 1985. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98852b0-182b-4906-a24b-e1f866c32e5c",
   "metadata": {},
   "source": [
    "#### After we made sure the transtioning betweek years(weeks) are smooth and correct, we start to combine expected dates together that might have report dates in 1984 and/or 1985. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce6865-84cd-4686-8015-2a56590387c9",
   "metadata": {},
   "source": [
    "#### Only then we will be able to perform framing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f41901-5464-4640-9d4a-48cbc6403f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to CSV files\n",
    "csv_path1 = '/Users/balmeru/Downloads/updated_1984.csv'\n",
    "csv_path2 = '/Users/balmeru/Downloads/updated_1985.csv'\n",
    "\n",
    "# Step 1: Load the CSV files into Pandas DataFrames\n",
    "df1 = pd.read_csv(csv_path1, index_col=0)\n",
    "df2 = pd.read_csv(csv_path2, index_col=0)\n",
    "\n",
    "# Step 2: Combine unique indices and columns\n",
    "combined_indices = df1.index.union(df2.index)  # All unique quarters\n",
    "combined_columns = df1.columns.union(df2.columns)  # All unique ticker symbols\n",
    "\n",
    "# Step 3: Create a new empty dataframe with NaN values\n",
    "combined_df = pd.DataFrame(index=combined_indices, columns=combined_columns)\n",
    "\n",
    "# Step 4: Fill the new dataframe with data from the original dataframes\n",
    "# Fill from df1\n",
    "for col in df1.columns:\n",
    "    combined_df[col] = combined_df[col].combine_first(df1[col])\n",
    "\n",
    "# Fill from df2\n",
    "for col in df2.columns:\n",
    "    combined_df[col] = combined_df[col].combine_first(df2[col])\n",
    "\n",
    "# Step 5: Save the combined dataframe to a new CSV file\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1984.csv'\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined pivot table saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae816ab-ccfa-4b57-8623-3ad171c8390b",
   "metadata": {},
   "source": [
    "#### First, let's identify max and min dates in expected dates for each year separately, then we will combine together those that contain dates for  target years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dc9de5-bf31-4d5e-a27b-1e8ec570ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3515314030.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1985-12-28 00:00:00\n",
      "Minimum Date: 1983-10-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1984.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a480ceab-428b-432f-bc5d-c534ff82e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\676529020.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1986-10-20 00:00:00\n",
      "Minimum Date: 1984-10-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1985.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3d3d-39b2-4bb1-b1b3-90b419114f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1986.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f939995f-c381-4bbc-9d37-cb4d3bb70a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1816051757.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1988-12-28 00:00:00\n",
      "Minimum Date: 1986-10-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1987.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9a72ad-3bd4-4b45-9e82-43931a93d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\310347647.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1989-10-19 00:00:00\n",
      "Minimum Date: 1987-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1988.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a7d83c-3b7a-49aa-ad46-efba9d9f1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1081597235.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1990-10-23 00:00:00\n",
      "Minimum Date: 1988-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1989.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92250219-051f-41f9-841c-a66e4e832ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2281286781.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1992-01-06 00:00:00\n",
      "Minimum Date: 1989-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1990.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22658f30-3ea7-4a5b-9237-9d00cdb21a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1269959078.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1993-04-01 00:00:00\n",
      "Minimum Date: 1990-10-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1991.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212f4129-3fe1-4eb6-a0b3-3a7a593e451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1159514142.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1993-12-20 00:00:00\n",
      "Minimum Date: 1991-10-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1992.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efd8890-7d3f-433b-99f4-95ca348b8f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3364849658.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1994-11-02 00:00:00\n",
      "Minimum Date: 1992-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1993.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8825ca6a-7ac4-4bec-ad69-4767e32481e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2804266630.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1995-10-27 00:00:00\n",
      "Minimum Date: 1993-10-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1994.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6a3931c-ba65-4c6e-bd79-e4e37e6a8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1175821547.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1998-08-24 00:00:00\n",
      "Minimum Date: 1994-10-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1995.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd6ee48-afc4-40a9-a4bf-befc3f2855e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2024712536.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1997-10-03 00:00:00\n",
      "Minimum Date: 1995-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1996.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fccc4c5-f4b7-49a4-8665-3155661d576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3340693850.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 1998-10-22 00:00:00\n",
      "Minimum Date: 1996-10-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1997.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e0394b9-2930-4120-badb-f8d5abc8cc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2107857917.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2001-05-24 00:00:00\n",
      "Minimum Date: 1997-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1998.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f259433-9c5b-43d9-9e4e-4183486ae361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3338610705.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2001-09-29 00:00:00\n",
      "Minimum Date: 1998-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_1999.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280f88cf-487b-4a6e-ae38-6758ce657550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2446091619.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2002-12-11 00:00:00\n",
      "Minimum Date: 1999-09-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2000.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d99284-9cac-44ed-8bb7-61e8f2ab33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\203923644.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2003-11-18 00:00:00\n",
      "Minimum Date: 2000-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2001.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73456937-d604-4109-b00b-b8243d7ac445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2103767951.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2004-11-16 00:00:00\n",
      "Minimum Date: 2001-10-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2002.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fbac5cd-b71d-4f2f-94bb-00db811334c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1645651549.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2006-07-25 00:00:00\n",
      "Minimum Date: 2002-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2003.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4156f49c-eb79-4510-b625-9e03d627a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3879522504.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2007-10-05 00:00:00\n",
      "Minimum Date: 2003-10-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2004.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33e3e0f4-4ff2-463c-bf0f-d0b35e8f72ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\459448585.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2008-03-07 00:00:00\n",
      "Minimum Date: 2004-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2005.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "900b0211-5c59-45eb-8b89-906f842f6def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\4050755943.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2011-03-16 00:00:00\n",
      "Minimum Date: 2005-10-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2006.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82daef84-fe14-4782-a3eb-cef365d467be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\1910853676.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2010-03-29 00:00:00\n",
      "Minimum Date: 2006-10-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2007.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf9db0c-fee7-49bd-aceb-85945831bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2834058364.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2011-01-19 00:00:00\n",
      "Minimum Date: 2007-10-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2008.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3adb3051-e78f-45e2-b5dc-91d4526b5a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\3755524799.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2011-08-15 00:00:00\n",
      "Minimum Date: 2008-10-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2009.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe513cf4-6ca7-4f6c-affe-6f03c5abe4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2870149727.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2012-08-17 00:00:00\n",
      "Minimum Date: 2009-10-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2010.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "111542b8-dd4b-40ec-83e1-63075ade2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\2032180126.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2014-11-07 00:00:00\n",
      "Minimum Date: 2010-10-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2011.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e136f95-8639-416f-8a88-fd6a80668e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balmeru\\AppData\\Local\\Temp\\ipykernel_6852\\212587331.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Date: 2015-02-02 00:00:00\n",
      "Minimum Date: 2011-10-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def find_max_min_dates(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    date_columns = []\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "            date_columns.append(column)\n",
    "        except:\n",
    "            continue\n",
    "    all_dates = pd.concat([df[col] for col in date_columns])\n",
    "    all_dates = all_dates.dropna()\n",
    "    max_date = all_dates.max()\n",
    "    min_date = all_dates.min()\n",
    "    return max_date, min_date\n",
    "csv_file = '/Users/balmeru/Downloads/updated_2012.csv'\n",
    "max_date, min_date = find_max_min_dates(csv_file)\n",
    "print(f\"Maximum Date: {max_date}\")\n",
    "print(f\"Minimum Date: {min_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c798653-1eee-4426-a48c-62e5266ea296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For 2012 we combine all expected dates file which have year 2012 (updated_2012, 2011, 2010)\n",
    "#### For 2011 we combine all expected dates file which have year 2011 (updated_2012, 2011, 2010, 2009, 2008)\n",
    "#### For 2010 we combine all years that might contain years 2009 and 2010 - they are expected dates updated_2011, 2010, 2009, 2008, 2007, 2006\n",
    "### Let's do it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b946284d-cddf-4379-99e0-498970e804c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2011.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2012.csv',  # Path to the first CSV\n",
    "    '/Users/balmeru/Downloads/updated_2011.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2010.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2009.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2008.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2011.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eddd55b1-274d-47fc-82e7-1e5068585454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2010.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2011.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2010.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2009.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2008.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2007.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2010.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7e5ffc2-acc0-4104-8f84-d1ee9335a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For 2009 we combine all years that might contain years 2009 and 2008 - they are expected dates updated_2010, 2009, 2008, 2007, 2006, 2005\n",
    "#### For 2008 we combine all years that might contain years 2007 and 2008 - they are expected dates updated_2009, 2008, 2007, 2006, 2005, 2004\n",
    "#### For 2008 we combine all years that might contain years 2007 and 2008 - they are expected dates updated_2009, 2008, 2007, 2006, 2005, 2004\n",
    "#### For 2007 we combine all expected dates file which have year 2007 (updated_2008, 2007, 2006, 2005, 2004)\n",
    "#### For 2006 we combine all expected dates file which have year 2006 (updated_2007, 2006, 2005, 2004, 2003)\n",
    "#### For 2005 we combine all expected dates file which have year 2005 (updated_2006, 2005, 2004, 2003)\n",
    "#### For 2004 we combine all years that might contain years 2003 and 2004 - they are expected dates updated_2005, 2004, 2003, 2002, 2001\n",
    "#### For 2003 we combine all years that might contain years 2002 and 2003 - they are expected dates updated_2004, 2003, 2002, 2001, 2000\n",
    "#### For 2002 we combine all years that might contain years 2001 and 2002 - they are expected dates updated_2003, 2002, 2001, 2000, 1999, 1998\n",
    "#### For 2001 we combine all expected dates file which have year 2001 (updated_2002, 2001, 2000, 1999, 1998)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "759f1bb6-06f8-472a-8086-8bd52b144079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2009.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2010.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2009.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2008.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2007.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2009.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3351ce5d-1439-4056-b98a-8fd86c4abee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2008.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2009.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2008.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2007.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2008.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d195899-39c9-4668-abea-ed928b0b00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2007.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2008.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2007.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2007.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9650137-8738-41be-a3c5-4224f1f18cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2006.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2007.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2003.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2006.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45022dd0-62f9-4850-acad-79779a3c1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2005.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2006.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2003.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2005.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3e9f5df-e356-40d7-9c72-93da80c86e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2004.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2005.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2003.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2002.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2001.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2004.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7696c7db-2a40-48df-aafb-6055c0ef2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2003.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2004.csv',  # Path to the second CSV\n",
    "    '/Users/balmeru/Downloads/updated_2003.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2002.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2001.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2000.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2003.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a8d1392-a668-4ab1-8d56-d880ef006392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2002.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2003.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2002.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2001.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2000.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1999.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2002.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e73a01-2165-490e-af97-521ddfd0f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For 2000 we combine all expected dates file which have year 2000 (updated_ 2001, 2000, 1999, 1998)\n",
    "#### For 1999 we combine all years that might contain years 1998 and 1999 - they are expected dates updated_2000, 1999, 1998, 1997, 1995\n",
    "#### For 1998 we combine all years that might contain years 1997 and 1998 - they are expected dates updated_1999, 1998, 1997, 1996, 1995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c20b7de-0e62-42cd-b5b3-6ee0786a72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2001.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2002.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2001.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2000.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1999.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2001.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bddb81d-478b-421a-bc0c-c4fe0f2a692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_2000.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2001.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_2000.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1999.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_2000.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97c14dca-7c48-4ebb-9f02-dfd684d76a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1999.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_2000.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1999.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1997.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1999.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e51c0e13-c740-45a1-8987-720d7f81c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1998.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1999.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1997.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1996.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1998.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48363f-638f-4fcc-b353-5e587e490a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For 1997 we combine all years that might contain years 1996 and 1997 - they are expected dates updated_1998, 1997,1996, 1995\n",
    "#### For 1996 we combine all expected dates file which have year 1996 (updated_1998, 1997, 1996, 1995)\n",
    "#### For 1995 we combine all expected dates file which have year 1995 (updated_ 1996, 1995, 1994 )\n",
    "#### For 1994 we combine all expected dates file which have year 1994 (1995, 1994, 1993)\n",
    "#### For 1993 we combine all years that might contain years 1992 and 1993 - they are expected dates updated_1994, 1993, 1992,1991, 1990\n",
    "#### For 1992 we combine all years that might contain years 1991 and 1992 - they are expected dates updated_1993, 1992,1991, 1990\n",
    "#### For 1991 we combine all years that might contain years 1990 and 1991 - they are expected dates updated_ 1992, 1991, 1990, 1989\n",
    "#### For 1990 we combine all expected dates file which have year 1990 (1991, 1990, 1989)\n",
    "#### For 1989 we combine all expected dates file which have year 1989 (1990, 1989, 1988)\n",
    "#### For 1988 we combine all years that might contain years 1987 and 1988 - they are expected dates updated_ 1989, 1988, 1987, 1986\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c4dbf2b-6ce7-49b4-8efb-15dd77c0aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1997.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1998.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1997.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1996.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1997.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16faec25-b3ce-4dfc-a953-136900e798df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1996.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1997.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1996.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1996.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f0fd6b9-1d51-4e4c-b576-04349e7ba834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1995.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1996.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1994.csv',  # Path to the third CSV\n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1995.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91683875-9688-48ae-bbaa-868f523fedd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1994.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1995.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1994.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1993.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1994.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b138ffac-dd68-4e65-a909-3f2cf5aa193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1993.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1994.csv',  # Path to the third CSV\n",
    "    '/Users/balmeru/Downloads/updated_1993.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1992.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1991.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1990.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1993.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3e0a458-3c12-495c-89ae-2b52f6c55e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1992.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1993.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1992.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1991.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1990.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1992.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c18a1edd-7be6-433b-9d9e-da5c64599077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1991.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1992.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1991.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1990.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1989.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1991.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44883715-d395-4db4-bd19-9f8cd15b50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1990.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1991.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1990.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1989.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1990.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ea40f13-eefe-4b7c-bf26-35bfb64e167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1989.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1990.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1989.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1988.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1989.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4a4a7d2-5adc-437c-8940-3e2554a967a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1988.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1989.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1988.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1987.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1986.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1988.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d00d8fd-fc5d-499a-9e79-e5147644ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For 1987 we combine all years that might contain years 1986 and 1987 - they are expected dates updated_  1988, 1987, 1986, 1985\n",
    "#### For 1986 we combine all years that might contain years 1985 and 1986 -  they are expected dates updated_ 1987, 1986, 1985, 1984\n",
    "#### For 1985 we combine all years that might contain years 1984 and 1985 -  they are expected dates updated_  1986, 1985, 1984\n",
    "#### For 1984 we combine all expected dates file which have year 1984 (1985, 1984)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3d5eb6c-56f9-48fd-a31f-d17c079d43a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1987.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1988.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1987.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1986.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1985.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1987.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89bc7fa5-d4de-438b-8e57-9e0deb7e2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1986.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1987.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1986.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1985.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1984.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1986.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "181bd95d-e0a8-412a-9872-a568782f48cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1985.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1986.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1985.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1984.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1985.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb2b5e39-8ad5-46f5-8885-1f979ad10547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to /Users/balmeru/Downloads/combined_1984.csv\n"
     ]
    }
   ],
   "source": [
    "csv_paths = [\n",
    "    '/Users/balmeru/Downloads/updated_1985.csv',  # Path to the third CSV \n",
    "    '/Users/balmeru/Downloads/updated_1984.csv',  # Path to the third CSV \n",
    "\n",
    "]\n",
    "dataframes = [pd.read_csv(path, index_col=0) for path in csv_paths]\n",
    "combined_columns = set()\n",
    "for df in dataframes:\n",
    "    combined_columns.update(df.columns)  # Update with unique column names\n",
    "\n",
    "combined_index = dataframes[0].index\n",
    "for df in dataframes[1:]:\n",
    "    combined_index = combined_index.union(df.index)  # Union of all indices\n",
    "\n",
    "combined_df = pd.DataFrame(index=combined_index, columns=sorted(combined_columns))\n",
    "\n",
    "# Fill the new DataFrame with data from all source DataFrames\n",
    "for df in dataframes:\n",
    "    combined_df.update(df)  # Use update to fill in existing data\n",
    "\n",
    "output_csv_path = '/Users/balmeru/Downloads/combined_1984.csv'  # Adjust path as needed\n",
    "combined_df.to_csv(output_csv_path)\n",
    "\n",
    "print(f\"Combined CSV saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adef09b-1f64-4c1a-9cbf-6e87a5cd5701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
